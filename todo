
- Support local variables at the beginning of a procedure.

  - in the Alloy analyzer the list of local variables is appended to
    the list of procedure state variables
  - in the C generator the list of local variables is appended to the
    temporary variables that we build when we simplify the concurrent
    assignment statement into a sequence of simple assignment statements.

however, adding a list of locals at the beginning of the body creates
a shift/reduce conflict because the ';' that terminates the list is
confused with the ';' that separates two definitions.

- A simple model of dynamically allocated objects?

  heap : seq Object
	{ heap = HEAP }
; alloc [p,T]
	{ p = NULL => heap = HEAP and p != NULL => (p !in int.HEAP and p in T and heap = add[p,HEAP]) }

abstracting (hiding) the heap we get

	{ true }
; alloc [p,T]
	{ p = NULL or (p != NULL and p in T) }

but then we have no way to indicate that p is disjoint from every
other object that was allocated up to this point. Can we use a
predicate for that?

	{ true }
; alloc [p,T]
	{ p = NULL or (p != NULL and p in T and fresh[p]) }

in the context of algorithmic programs can we assume that allocation
succeeds? for if it fails the algorithm itself fails. Is it not
then a separate concern that should be handled by other means?

	{ true }
; alloc [p,T]
	{ p in T and fresh[p]) }

no, that won't do because we cannot support such a specification
in a finite model. there is always the chance that we will run out
of memory.

- make 'sum' a term
- prove that wpca is correct:
  - prove that it calculates correctly the weakest precondition
  - prove that every well typed program generates a valid C program
  - prove that every well typed program generates a valid Alloy model

- how to avoid record field names from different records from clashing?

the problem is that in alloy sigs are not name spaces so for example
the following wpca program:

record A {
  f : B
}

record C {
  f : int
}

will create an ambigous alloy model because there are two relations
called f.

  one way to solve this problem is to attach to every relation a prefix 
with the record in which it was defined. But this will make the 
counterexamples difficult to read.

this may not be a problem in practice because as long as the relations
are used in the context of a relational composition the type of the
objects with which they are composed will resolve the ambiguity.

- how to protect Alloy generated names from clashing with user defined
names? for example what if a user decides to define a variable called
'State'? 

  one way is to reduce the chances of this happening by giving the alloy
variables awkward names. For example instead of using 'State' we may 
use '__wpca__State'. We may even forbid wpca variable names not to begin
with '__wpca__'. 

 a similar way is to use in alloy a character that is forbidden in wpca
names, for example to start every internal variable with W'.

- the grammar of wpca with support for records, procedures and
explicit inclusion of alloy definitions is:

Program : Records Procs Theory

Records : Records Record | Record

Procs : Procs Proc | Proc

Theory : 'theory' name

Record : 'record' name '{' Declarations '}'

Proc : 'proc' name '[' Declarations ']' '{' Expr '}' Stmt '{' Expr '}'
	
each procedure is analyzed separately, for each procedure we create
a separate analysis file. 

- generate the program file based on the wpca file name. for example,
the wpca file stack.w yields the C files stack.h and stack.c.

- better support for records

define records to support fields and the null idiom.

record Node {
  data : T,
  next : Node
}

is translated into the following alloy model:

one sig NULL {}

sig Node {}

sig State {
  data : Node -> T,
  next : Node -> (Node + NULL)
}

in addition, every definition of a variable of type Node in the
program becomes a definition of a variable of type Node+NULL in the
model.

in general, whenever we define a variable of type record we must
add an option for this variable to be set to NULL.

- the alloy modules that define the predicates and functions of a
wpca program must be specified in the program itself.

one simple way to achieve this is to add a theory keyword at the
end of the program:

x,y,z : int
	{ true }
; if x < y -> z := y [] x >= y -> z := x fi
	{ z = max[x,y] }

theory maxmin

where maxmin.als is an alloy file that defines the function max

- how similar should wpca be to a programming language?

- what is the best way to combine wpca with alloy?

  - one way (as implemented in DynAlloy) is to embed wpca inside the
  alloy language. this makes it easy to use all of the alloy constructs
  (including scope definitions, predicates, functions, signature
  definitions etc'). we can use the keyword 'proc' to define wpca
  procedures:

proc swap[x:T,y:T] 
	{ x = X and y = Y }
{ x,y := y,x }
	{ x = Y and y = X }

the problem is that using this approach will make it more difficult to
generate code, in particular to generate data structure definitions. the
central issue is that the constructs that define data structures are
limited to ensure that we can generate from them efficient code. for
example we cannot translate any sig into a struct because the sig may
contain arbitrary relations.
 
- support heap allocated objects. 

This requires a wp model of the heap, a model of records and syntax for
the wpca language:

The signature 'Object' is the set of all objects that are allocated
dynamically from the heap. The set 'heap' holds all the objects that
are currently allocated.

heap : set Object
 
The keywords new and delete allocate and de-allocate objects:

x := new Object
= any obj : Object - heap | heap,x := heap + obj, x

there are two important points here:

1. This is a new non-deterministic command. 

2. What happens if Object = heap? 

We can handle this problem by generating a proof obligation that requires
that there are available objects.

In other words, this is a partial non-determinstic statement:

wp(any x : X | S, P) = some x : X | wp(S,P)

The delete statement de-allocates an object:

wp (delete x,P)
= x in heap and P[heap/heap - x]


We must now discuss how we model records that reference objects because
without such records there is no point to all this heap business.

A record has the following wpca syntax:

record <name> {
  (<name> : (one | lone | set) <type>,)*
  <name> : (one | lone | set) <type>
}

for example:

record node {
  data : one int,
  next : lone node
}

This has the following alloy semantics:

sig node extends Object {
  data : one int,
  next : lone node
}

Consider now a program that uses records:

  i : int
; x : node
	{ x in heap }
 ; i := x.data
 ; x.data := 1
  
The semantics of record fields is similar to arrays:

 x.data := 1
=
 data := data ++ (x -> 1) 

Adding heap allocated records raises the following questions:

1. What if we delete an object x that is accessible from a reachable object?

We should ensure that we never delete an object that is accessible from
a reachable object. There are two ways we may approach this problem:

1.1. Add this assertion before every delete statement.

1.2. Add a proof obligation to every expression that uses heap
objects. The proof obligation checks that the object is allocated.

Either option means that we must be able to model the set of objects
that are accessible to the program. These objects are the ones that are
referenced directly or indirectly by the state variables of the program.

The second option is more flexible because it supports programs where
we first delete an object and then remove it from the objects that
reference it.  However, it will generate diagnostics that are more
difficult to trace because it will be difficult to locate the delete
statement that was responsible for the violation.

But how do we indicate that we no longer want to refer to an object? We
don't want to use a NULL id because this sentinel tends to leak into the
data. Instead we will provide a special operation to clear a reference
and a special operation to test if a reference exists:

2. What if we clear all the references to an object? without a garbage
collector this will create a leak!


- change the definition of an array such that the size variable is a constant.

Instead of

  N : nat
; a : array of N int

Write

  a : array of N int

and the meaning is that N becomes a constant of type whose size can never be
negative.

- support user defined types

- support concurrency based on the Gries/Owiki theory

  - how do we define which operations are atomic?

  - how should we name the individual components?

  - should we support parameterised components? how?

- change the report to reflect the true meaning of the counter-example.

The counter-example represents a state of the program that satisfies
all the guards along a particular path to a goal but does not satisfy
the goal.

- compare wpca to: B-Toolkit, Forge, DynAlloy, Spark

- extend the wpca language to have a section of alloy definitions.
this has several benefits:

1. When the Alloy definitions in the code are separate from the
code there is a danger of losing them, thus losing the meaning of
the model. When everything is in the same file this danger is
eliminated.

2. It is easier to understand the code when all the definitions are
visible at once.

3. There is no need to affect a global resource (such as a global
definition include file). This improves modularity.

We may implement this extension as follows:

<wpca code>

'where'

<alloy code>

Open issues: should the alloy code be passed 'as is' to alloy? 

One problem is that in wpca the name of the set of integers is 'int'
but in Alloy it is 'Int'.

- change the names of the top level variable declaration to indicate
that these are the state variables.

- simplify the declaration section to be a list of pairs where each pair
associates a name to its type (or set expression).

- the transformers that convert a wpca program into a simple form should
be refactored into a separate module because they will be reused by many
language generators.

- change the names of the tests so that it will be clear what they
stand for.

- add support for relations

- add support for sets

requires a data structure C library that supports sets. We may use
gnulib which contains implementations of a set ADT.

once we support sets we should be able to write and check an abstract
version of the quicksort algorithm (where a set is used to hold the
parts that we still need to sort).

- add support for procedures

once we support procedures and arrays we should be able to write and
check the partition algorithm.

to support procedures we need to:

1. decide on a syntax of a procedure in particular how we specify
input and output variables.

procedure partition(a : in out array of N int, i : out int)
	require a = A and N > 1 and A[0] = Pivot
{
  // ... code
}
	ensure 0 < i < N and permutation[a,A] and (all j : 0..i-1 | a[j] <= Pivot) and all j : i..N-1 | a[j] >= Pivot

If we omit the body of the procedure then we may use its require and
ensure clauses as its specification.

2. define the wp semantics of a procedure:

We have two independent things:

2.1. Check that the procedure's body satisfies its specification

This is easy: Convert the parameters into state variables and run
the existing checks.

2.2. Define the wp semantics of the procedure _assuming_ that it
satisfies its specification.

Let V be a vector of n variables and let E be a vector of N 
expressions.

procedure p[V]
	require Pre
	ensure Post

wp (p[E], Q) = Pre[V/E] and all out(E) | Post[V/E] => Q[V/E]

where out(E) is the list of expressions that appear in the
call in the position of an out variable.

Consider:

procedure max[x,y : in, z : out]
	require { true }
	ensure { z >= x and z >= y and (z = x or z = y) }

and the call

max[1,2,u]
 
Here: 

V = x,y,z
E = 1,2,u
out(E) = u

wp (max[1,2,u], u > 3) 
= all u | u >= 1 and u >= 2 and (u = 1 or u = 2) => u > 3

another example:

procedure unique[a : in out array of N int, n : out int]
	require 
		a = A and all i,j : 0..N-1 | i <= j => a[i] <= a[j]
	ensure 
		(all i,j : 0..n-1 | i!=j => a[i] != a[j]) and all i : 0..N-1 | some j : 0..n-1 | A[i] = a[j]	

how do we deal with array size variables such as N? 
	substitute for the size of the array in the call
how do we deal with constant variables such as A? 

x,y : array of K int
; unique[x]
; unique[y]

a more simple example that demonstrates the problem:

procedure inc[x:in out int]
  require x = X
  ensure x = X + 1

x : int
	{ x = Y }
  inc[x]
; inc[x]
	{ x = Y + 2 }

wp (inc[x];inc[x], x = Y + 2)
= wp (inc[x], wp(inc[x], x = Y + 2)
= wp (inc[x], some X | x = X and all x : int | x = X + 1 => x = Y + 2)
= wp (inc[x], some X | x = X and X+1 = Y+2 }
= wp (inc[x], some X | x = X and X = Y+1 }
= wp (inc[x], x = Y+1)
= some X | x = X and all x : int | x = X + 1 => x = Y + 1
= some X | x = X and X = Y
= x = Y

So we must existentialy quantify the constants. However because the
constants are always defined by an equation we can shortcut the
quantifier and instead directly substitute for the constant's value:

wp (inc[x];inc[x], x = Y + 2)
= wp (inc[x], wp(inc[x], x = Y + 2)
= wp (inc[x], (all x : int | x = X + 1 => x = Y + 2)[X/x])
= wp (inc[x], (all u : int | u = X + 1 => u = Y + 2)[X/x])
= wp (inc[x], (all u : int | u = x + 1 => u = Y + 2))
= wp (inc[x], x+1 = Y+2)
= wp (inc[x], x = Y+1)
= (all x : int | x = X + 1 => x = Y + 1)[X/x]
= (X = Y)[X/x]
= x = Y

procedure swap[x,y : in out int]
	require x = X and y = Y
	ensure x = Y and y = X

a,b,c : int
	{ a = A and b = B and c = C }
; swap[a,b]
; swap[b,c]
	{ a = B and b = C and c = A }


wp (swap[a,b]; swap[b,c], a = B and b = C and c = A)
= wp(swap[a,b], wp(swap[b,c], a = B and b = C and c = A))
= wp(swap[a,b], some U,V | b = U and c = V and 
		all b,c:int | b = V and c = U => a = B and b= C and c = A)
= wp(swap[a,b], some U,V | b = U and c = V and 
				a = B and V = C and U = A)
= wp(swap[a,b], a = B and c = C and b = A)
= wp(swap[a,b], a = B and b = A and c = C)
= a = A and b = B and c = C


- refactor the code to reflect the architecture

- improve the structure of the alloy module. 
currently we identify the different kinds of variables in an ad-hoc manner.

- find or write a template mechanism for the part that generates the alloy code

- is it beneficial to use cabal instead of make?

- how do we integrate typechecking? as a separate tool? using an attribute grammar?

- create a java module 

- we need to deal with counterexamples that occur because of
overflows. when alloy's latest version comes out we can use the 'no
overflow' feature. should we do something else in the meantime?

- should we check for a particular alloy version?

- how can we translate alloy's solution to a test case? 
this of course depends on the platform. 

- display the result of analysis in a way that is meaningful to the author of the program.

this problem requires a deeper analysis than I have previously thought. 

we need to display the following information:

- which property was violated (include its location and name: is it a loop invariant or a postcondition?)
- which line of code caused the violation (include its location)
- what is the path that the program follows to get to the offending line of code?
- what are the values that cause the program to follow this path? 

Done

- support record fields

To support an algorithm over dynamic data structures we add a new
kind of variable: a relation variable. For example:

next : Node <-> Node

defines next to be a variable that holds relation between Node
objects. Note: we cannot use the Alloy '->' symbol because it is
already taken by the guarded command langauge.

In a traditional programming language these variables are global.
Therefore when we generate code we omit them from the list of state
variables. For example, consider the following program:

  head : Node
; next : Node <-> Node
; head.next = NULL

The C code that corresponds to this program is:

typedef struct _state {
  Node* head;
} state;

algo(state* s) {
  s->head->next = NULL
}

To do that we have to:

1. Support Cartesian product expressions
  - Identify '<->' as a token
  - Allow '<->' in Expr and define its associativity and precedence
  - Add '<->' to the AST
  - Print '<->' in alloy
  - Display counter-examples that involve relations that are not arrays
  - In C Ignore variables whose type is a Cartesian product 

2. Distinguish between array join and relational join
  - Create a token for array 'join'
  - In Alloy convert array join to relational join
  - In C display array join using array syntax and relational join as
    access to a struct field 

3. In the C generator print array join as before and
relational join using the arrow operator.

- support record fields

To support an algorithm over dynamic data structures we add a new
kind of variable: a relation variable. For example:

next : Node <-> Node

defines next to be a variable that holds relation between Node
objects. Note: we cannot use the Alloy '->' symbol because it is
already taken by the guarded command langauge.

In a traditional programming language these variables are global.
Therefore when we generate code we omit them from the list of state
variables. For example, consider the following program:

  head : Node
; next : Node <-> Node
; head.next = EOL

The C code that corresponds to this program is:

typedef struct _state {
  Node* head;
} state;

algo(state* s) {
  s->head->next = NULL
}

To do that we have to:

1. Support Cartesian product expressions
  - Identify '<->' as a token
  - Allow '<->' in Expr and define its associativity and precedence
  - Add '<->' to the AST
  - Print '<->' in alloy
  - Display counter-examples that involve relations that are not arrays
  - In C Ignore variables whose type is a Cartesian product 

2. Distinguish between array join and relational join
  - Create a token for array 'join'
  - In Alloy convert array join to relational join
  - In C display array join using array syntax and relational join as
    access to a struct field 

3. In the C generator print array join as before and
relational join using the arrow operator.
 

- support comparable objects 

By using an abstract comparable object we can significantly improve the
speed of the analysis because without a comparable object we are forced
to use integers but by default there are 16 integers which makes the
analysis slow.

- support constant variables of arbitrary expressions

for example:

a : array of N T

	{ a = A and A[0] = Pivot }

should make Pivot a constant of type T

- support ternary relational expressions.

instead of writing

0 < i and i < N

write

0 < i < N

how to support a ternary operator like this one?

expr : term '<' term | term '<' term '<' term | term

term : term '+' term | term '-' term | integer


- add support for displaying skolem variables. these occur when the
counterexample contradicts a universal quantifier.

when a counterexample contradicts a universal quantifier alloy
outputs the keyword skolem followed by an equation of the form

'$' <the name of the assertion> '_' <the name of the local variable> '=' tuples

because the local variables are not state variables their tuples do
not begin with a state.

the Relation data type has a field that indicates the kind of the relation, we
can set this field to "Local" to mark it as a relation that belongs to a
local variable. Then we can print it properly in Analyzer.hs

- add support for arrays

this includes:

1. array declaration:

a : array of n int

<name> : array of <size> <type>

<size> : <name>

- the size variable must refer to an integer variable. 
- the precondition is expanded to demand that <size> is not negative.

the relational meaning of an array variable is a sequence. for example:

N : int; A : array of N int

generates the following Alloy state signature:

one sig State {
  N : Int,
  A : seq Int
}

fact {
 all s : State | #s.A = s.N
}

perhaps it is better to define the type nat to stand for natural numbers
including 0. then we can write:

N : nat; A : array of N int

and generate the additional fact

all s : State | s.N >= 0

we can then check that the variable that defines the size of the array is
of type nat.

2. array reference:

- when an array appears in the code it must be inside an array reference.
- when an array appears in a spec it does not have this limitation.
- each reference to the array generates a proof obligation to ensure that the reference is within the array's bounds.

for example, the code:

N : int;
A : array of N int
; x,y := A[i], A[i+j]

generates two proof obligations:

0 <= i and i < N
0 <= i+j and i+j < N

- the relational meaning of an array expression is a relational join. we do not have to change the syntax as the meaning of A[i] in Alloy is precisely what we need.

3. array assignment:

- an array variable can appear at most once in an r-value.

for example, assume that A and B are arrays.  this is ok:

A[i],B[j] := e1,e2

this is illegal:

A[i],A[j] := e1,e2

- the relational meaning of an array assignment is an update:

A[i] := e

becomes

A := A ++ i->e

relax this requirement and instead collect all the assignments to 
the same array in a single update:

A[i],A[j] := e1,e2

becomes

A := A ++ (i->e1 + j->e2)

this makes it possible to swap array elements using the same
code as to swap variables:

A[i],A[j] := A[j], A[i]

Note that because we require that A is a sequence we automatically
exclude cases where (i = j and e1 != e2). To detect these errors
we must add a proof obligation: (i != j or e1 = e2) of course we
must extend this to the general case.

a more simple solution is to require that the update relation is a function:

(i->e1 + j->e2 + ... + k->en) in Int -> lone Int

for an array of integers.

- refactor the code into separate programs and use a shell script to bind them together.

  this will greatly simplify the code and the names of each program.

- refactor the code to reflect the architecture

- improve the structure of the alloy module. 
currently we identify the different kinds of variables in an ad-hoc manner.

- find or write a template mechanism for the part that generates the alloy code

- is it beneficial to use cabal instead of make?

- how do we integrate typechecking? as a separate tool? using an attribute grammar?

- create a java module 

- we need to deal with counterexamples that occur because of overflows. when alloy's latest version comes out we can use the 'no overflow' feature. should we do something else in the meantime?
- should we check for a particular alloy version?
- how can we translate alloy's solution to a test case? 
this of course depends on the platform. 

- display the result of analysis in a way that is meaningful to the author of the program.

this problem requires a deeper analysis than I have previously thought. 

we need to display the following information:

- which property was violated (include its location and name: is it a loop invariant or a postcondition?)
- which line of code caused the violation (include its location)
- what is the path that the program follows to get to the offending line of code?
- what are the values that cause the program to follow this path? 

Done

- add support for quantifiers

  - quantifiers can appear only in assertions

  - we must change the substitution algorithm to avoid capturing free variables and to generate unique names that are easy to relate to the original names.

    alternatively we can flag this as an error and ask the progammer to give diffferent names to her local variables.

- change the configuration file syntax to support strings with space 
  this requires start codes but they work only with a monad lexer. 

- add location information to the ast nodes

- change the code to use the new rose-tree like structure of the ast

- create a separate assertion for each code segment. 

we may name the assertions according to the line number in which the code segment begins
we can keep the line number of each statement in the corresponding node.

- activate alloy from wpca

- what is the architecture of wpca? 

see here:

https://docs.google.com/drawings/d/1h_HZwbjf_Jyvit_fmtb6thQtI1TqhqZXDZqjQyWldF0/edit?hl=en_GB


the general architecture is a central repository (the ast) on which various tools operate :
  the lexer and parser build the repository
  and the platform dependant tools generate code from the repository (should we model where they store their output or is that beyond the scope of the system?)
  within each tool the architecture is specific to the tool. for example, the alloy tool
  has a layered architecture :

   first (lowest) layer: functions that calculate free variables, substitutions and so on
   second layer: the weakest precondition calculator
   third (highest) layer: generating the alloy code, invoking the analyzer and reporting the results.

- separate the alloy checks according to the code segments. this way it will be easier to understand which part of the program is incorrect

we can use the theorem 

wp(s,p and q) = wp(s,p) and wp(s,q) 

to separate obligation checks into multiple alloy checks.
- support analysis functions and relations: if a name is not a state variable and it is not a constant (that is, it does not appear in an equality expression with a state variable) then we assume that it is a modeling variable.
- put parenthesis around expressions 
- move project to github
- read from file
- create configuration file to guide translation?
- need to control: scope, sat solver, platform, name of analysis file, should analysis file be kept or deleted, 
- given platform need to control:
-  name of file,procedure,class,method, package and so on

